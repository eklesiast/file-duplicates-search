# file-duplicates-search
Search for duplicate files (PHP)

Найстроки и запуск

Работает в консольном режиме (по желанию можно запустить из веба тоже).

Для запуска перейти в директорию с проектом, запустить команду:
> php duplicates.php /home/luke/Documents/

где “/home/luke/Documents/ ” ­ абсолютный путь к директории для поиска.

По умолчанию поиск осуществляется в директории scandir в папке проекта.
Результат работы записывается в файл duplicates.txt

Проверено на PHP 5.6, Apache 2.4, Ubuntu 12.04.


Под капотом

Упрощенный алгоритм выглядит так:

1) Получение списка файлов
2) Проверка файлов по размеру
3) Проверка файлов по хэшу
4) Сохранение результатов

На самом деле программа более гибкая.

Поставщик списка файлов (provider) может быть разным. В конкретной задаче выполняется поиск в директории. 
При необходимости можно добавлять новые классы provider'ов (например, если список путей
проверяемых файлов находится в базе данных, файле, т.д.).

Следующий шаг – проверка файлов на дубликаты. За это отвечает компонент
DuplicateFinder. Он содержит массив процессоров и массив с путями к файлам. Вызывая
метод DuplicateFinder::run() мы запускаем поиск дубликатов. Он состоит в том, чтоб по
очереди к массиву файлов применять процессоры, которые будут отсеивать из массива те
записи, которые не являются дубликатами. Плюс этого подхода состоит в том, что каждому
следующему процессору “достается” уже отфильтрованный массив с меньшим количеством
элементов. Логично, что процессоры с самыми быстрыми алгоритмами стоит запускать
раньше.

В данной реализации мы “скармливаем” DuplicateFinder'у 3 процессора: процессор для
проверки по размеру файла, процессор для сравнения по хэшам (алгоритм adler32, который
судя по википедии и нескольким тестам является наиболее быстрым) и еще раз процессор
для сравнения по хешам, но с алгоритмом md5.

В зависимости от выдвигаемых условий (точности поиска, количества файлов, уровня
критичности ошибки, ...) мы можем оптимизировать работу процессоров.

Последний шаг – сохранение результатов.


Выводы

На мой взгляд код написан с учетом основных принципов программирования и здравого смысла.
В продакшене использовать его сразу я бы не стал, возможно требуются доработки и
тщательные тесты. 